
PAN Plagiarism Corpus 2011

Copyright 2011 Bauhaus-Universität Weimar & Universidad Politécnica de Valencia
All rights reserved.

http://pan.webis.de


Table of Contents:
1. Introduction
2. Plagiarism Generation
3. Corpus Format
4. Acknowledging the Corpus
5. Contact Information


1. Introduction

This corpus contains documents in which plagiarism has been inserted
automatically and manually. We believe these documents will be useful to
evaluate automatic plagiarism detection algorithms.


1.1 Source Documents

The documents in the corpus are based on books from the Project Gutenberg 
(www.gutenberg.org). In total it is based on 22,000 English books, 520 German 
books, and 210 Spanish books.


1.2 License of the Corpus

All of the texts contained in this corpus are, to the best of our knowledge, 
public domain. The corpus can therefore be used free of charge and without any
liabilities.


1.3 Plagiarism in the Corpus

As far as we know this corpus does not contain any real plagiarism cases. By
contrast, all of the annotated plagiarism cases are either artificial, i.e.,
generated by a computer program, or simulated, i.e., purposefully made by a
human We emphasize that we do not claim that any author whose work is contained
in this corpus has actually committed plagiarism. Any resemblance to real
plagiarism cases is coincidental.


1.5 Algorithms to be Evaluated with the Corpus

The corpus can be used to evaluate the following plagiarism detection task:
Given a set of suspicious documents and a set of source documents, the task is
to find all plagiarized sections in the suspicious documents and, if available,
the corresponding source sections.

Note that this involves two distinct plagiarism detection paradigms at the same
time:

(i) External plagiarism detection:
Given a set of suspicious documents and a set of source documents the task is to
find all text passages in the suspicious documents which have been plagiarized
and the corresponding text passages in the source documents.

(ii) Intrinsic plagiarism detection:
Given a set of suspicious documents the task is to identify all plagiarized text
passages, e.g., by detecting writing style breaches. The comparison of a
suspicious document with other documents is not allowed in this task. 



2. Plagiarism Construction

Most of the plagiarism cases in this corpus have been generated automatically
which is why we call them "artificial plagiarism cases". Other kinds of
plagiarism cases include simulated plagiarism cases, but there are no real
plagiarism cases.


2.1 Artificial Plagiarism

In order to create artificial plagiarism cases, we have set up a computer
program which chooses text passages from a given set of source documents at
random and inserts them into another set of documents. This so-called random
plagiarist constructs the plagiarism cases according to to a number of random
variables whose distributions can be chosen by its operator. The variables
include the percentage of plagiarism in the whole corpus, the percentage of
plagiarism per document, and the length of a single plagiarized passage.

An important variable is the degree of obfuscation of a single plagiarized
passage. Real plagiarists often try to obfuscate their plagiarism by rephrasing
the passages they copy. The random plagiarist tries to simulate this action
by combining a number of different automatic obfuscation strategies. Observe in
this connection, that the obfuscated plagiarism cases produced by the random
plagiarist are not necessarily human-readable. The reason for this is that
writing a text automatically is still an unsolved problem. However, with respect
to standard text similarity retrieval models of information retrieval, such as
the vector space model, the random plagiarist creates cases where the obfuscated
passage does not remotely resemble the original but whose measured similarity is
still high.

Note that in the part of the corpus intended for intrinsic plagiarism detection
evaluation the plagiarism case have not been obfuscated automatically in order 
not to destroy the writing style.


2.2 Simulated Plagiarism

In order to create simulated plagiarism cases, we have employed crowdsourcing,
namely Amazon's Mechanical Turk. Text passages which were chosen at random from
a source document have been presented to a human whose task was to rewrite the
passage so that the wording would be different but the semantics preserved. The
rewritten text passages have then been inserted into the suspicious documents.
This way, the obfuscation of the plagiarism cases obtained closely resembles
the way human plagiarists would work.


3. Corpus Format

3.1 Contents of the Top-level Directory

Directories "external-detection-corpus" and "intrinsic-detection-corpus" which
denote the portions of the corpus dedicated to the respective sub-tasks of 
plagiarism detection. The "external-detection-corpus" directory contains the
directories "source-documents" and "suspicious-documents": they contain
documents which may have been used as a source for plagiarism and documents
which may contain plagiarism, respectively. The "intrinsic-detection-corpus"
directory contains only a "suspicious-documents" directory. The source documents
are not required for the intrinsic plagiarism detection task. Each of the two
directories also contains a file "retrieval-task.txt", which is a description
of the task to be evaluated using the corpus.

File "document.xsd": XML schema for the XML files found in the corpus.


3.1.1 Contents of the "source-documents" directory

Directories "partX", where X is an integer, that contain the following
kinds of files:

File "source-documentKKKKKK.txt": a text file encoded in UTF-8 which may have
been used as a source for plagiarism cases.

File "source-documentKKKKKK.xml": an XML file which gives meta information about
the corresponding text file.


3.1.2 Contents of the "suspicious-documents" directory

Directories "partX", where X is an integer, that contain the following
kinds of files:

File "suspicious-documentKKKKKK.txt": a text file encoded in UTF-8 in which
plagiarism may have been inserted.

File "suspicious-documentKKKKKK.xml": an XML file which annotates the plagiarism
inserted in the corresponding text file. Note that a text file may not contain
any plagiarism.



4. Acknowledging the Corpus

We are very pleased to release this corpus free of charge, and it is our hope
that it will foster the development of new plagiarism detection approaches.
We would be happy to hear from you about how and with what success you used the
corpus. If you use the corpus we kindly ask you to refer to it in your
publications as follows:

Citation template:

Martin Potthast, Benno Stein, Alberto Barrón-Cedeño, and Paolo Rosso.
An Evaluation Framework for Plagiarism Detection. In Proceedings of the 23rd
International Conference on Computational Linguistics (COLING 2010), Beijing,
China, August 2010. Association for Computational Linguistics.

Bibtex:

@INPROCEEDINGS{pan:2010,
  TITLE     = {{An Evaluation Framework for Plagiarism Detection}},
  AUTHOR    = {Martin Potthast and Benno Stein and
               Alberto Barr{\'o}n-Cede{\~n}o and Paolo Rosso},
  BOOKTITLE = {Proceedings of the 23rd International Conference on
               Computational Linguistics (COLING 2010)},
  MONTH     = aug,
  YEAR      = {2010},
  ADDRESS   = {Beijing, China},
  PUBLISHER = {Association for Computational Linguistics},
}



5. Contact Information

If you have comments, suggestions, questions about the corpus, or any other
feedback don't hesitate to send mail to pan@webis.de.


Martin Potthast, Andreas Eiselt, Benno Stein, Alberto Barrón-Cedeño, Paolo Rosso
Bauhaus-Universität Weimar and Universidad Politécnica de Valencia
July 22, 2011

